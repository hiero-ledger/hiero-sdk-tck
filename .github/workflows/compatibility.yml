# SPDX-License-Identifier: Apache-2.0
name: "System Compatibility"
on:
  pull_request:
    branches: [main]
  workflow_call:
    inputs:
      ref:
        description: "The branch, tag, or SHA to checkout:"
        required: false
        type: string
      custom-job-name:
        description: "The custom job name to use for the job:"
        required: false
        type: string
    secrets:
      access-token:
        description: "GitHub Access Token with write permissions to the repository."
        required: true

defaults:
  run:
    shell: bash

permissions:
  checks: write
  contents: read
  actions: write
  statuses: write
  id-token: write

env:
  SOLO_CLUSTER_NAME: "solo-tck-e2e"
  SOLO_NAMESPACE: "solo-tck-e2e"
  SOLO_DEPLOYMENT: "solo-tck-deployment"
  SOLO_CLUSTER_SETUP_NAMESPACE: "solo-setup"
  GRADLE_EXEC: ionice -c 2 -n 2 nice -n 19 ./gradlew

jobs:
  # Execute TCK Regression Tests using specified version of hiero-consensus-node
  tck-regression:
    name: ${{ inputs.custom-job-name || 'Standard' }}
    runs-on: hiero-client-sdk-linux-large
    steps:
      - name: Harden Runner
        uses: step-security/harden-runner@ec9f2d5744a09debf3a187a3f4f675c53b671911 # v2.13.0
        with:
          egress-policy: audit

      # Checkout the current TCK repository
      - name: Checkout TCK Repository
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      #  Check out the specified hiero-consensus-node reference
      - name: Checkout Consensus Node
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          path: consensus-node
          repository: hiero-ledger/hiero-consensus-node
          ref: ${{ inputs.ref || '' }}
          fetch-depth: 0

      # Checkout the JS-SDK server
      - name: Checkout JS-SDK Server
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          path: sdk-server
          repository: hiero-ledger/hiero-sdk-js
          fetch-depth: 0
          fetch-tags: true

      - name: Checkout Latest Tag (JS-SDK)
        run: |
          cd sdk-server
          git fetch --tags
          LATEST_TAG=$(git describe --tags `git rev-list --tags --max-count=1`)
          echo "Latest JS-SDK tag: $LATEST_TAG"
          git checkout $LATEST_TAG

      # Set up Java Environment
      - name: Setup Java
        uses: actions/setup-java@c5195efecf7bdfc987ee8bae7a71cb8b11521c00 # v4.7.1
        with:
          distribution: temurin
          java-version: 21.0.6

      # Set up the node environment
      # Version 20.18.0 is the recommended version for solo.
      - name: Setup NodeJS Environment
        uses: actions/setup-node@49933ea5288caeca8642d1e84afbd3f7d6820020 # v4.4.0
        with:
          node-version: 20.18.0

      - name: Setup PNPM
        run: |
          npm install -g pnpm

      # Set up the gradle environment
      - name: Setup Gradle
        uses: gradle/actions/setup-gradle@ac638b010cf58a27ee6c972d7336334ccaf61c96 # v4.4.1
        with:
          cache-read-only: false

      # Build the hiero-consensus-node artifacts
      - name: Build hiero-consensus-node
        run: ${GRADLE_EXEC} assemble
        working-directory: consensus-node

      # Set up the npm dependencies and cache on the tck-client
      - name: Set up the tck-client
        run: |
          npm cache clean --force
          npm install

      # Set up the npm dependencies and cache on the sdk-server
      - name: Install NodeJS Dependencies (sdk-server)
        id: start-sdk-server
        run: |
          # Extract package versions from the parent package.json
          SDK_VERSION=$(node -e "console.log(require('../package.json').version)")
          LONG_VERSION=$(node -e "console.log(require('../package.json').dependencies.long)")
          PROTO_VERSION=$(node -e "console.log(require('../package.json').dependencies['@hashgraph/proto'])")

          echo "Using SDK version: $SDK_VERSION"
          echo "Using long version: $LONG_VERSION"
          echo "Using proto version: $PROTO_VERSION"

          # Install with the extracted versions
          pnpm add @hashgraph/sdk@^${SDK_VERSION} long@${LONG_VERSION} @hashgraph/proto@${PROTO_VERSION}
          pnpm install
          nohup pnpm start &
          server_pid=$!
          echo "pid=${server_pid}" >> "${GITHUB_OUTPUT}"
        working-directory: sdk-server/tck

      # Install solo and configure to use the artifacts from
      # the hiero-consensus-node build
      - name: Install Solo
        run: npm install -g @hashgraph/solo@0.37.1

      # Set up kind; needed for configuring the solo environment
      - name: Setup Kind
        uses: helm/kind-action@a1b0e391336a6ee6713a0583f8c6240d70863de3 # v1.12.0
        with:
          install_only: true
          node_image: kindest/node:v1.31.4@sha256:2cb39f7295fe7eafee0842b1052a599a4fb0f8bcf3f83d96c7f4864c357c6c30
          version: v0.26.0
          kubectl_version: v1.31.4
          verbosity: 3
          wait: 120s

      # Set up solo
      - name: Configure and run solo
        run: |
          kind create cluster -n "${{ env.SOLO_CLUSTER_NAME }}"
          solo init
          solo cluster-ref connect --cluster-ref kind-${{ env.SOLO_CLUSTER_NAME }} --context kind-${{ env.SOLO_CLUSTER_NAME }}
          solo deployment create -n "${{ env.SOLO_NAMESPACE }}" --deployment "${{ env.SOLO_DEPLOYMENT }}"
          solo deployment add-cluster --deployment "${{ env.SOLO_DEPLOYMENT }}" --cluster-ref kind-${{ env.SOLO_CLUSTER_NAME }} --num-consensus-nodes 1
          solo node keys --gossip-keys --tls-keys -i node1 --deployment "${{ env.SOLO_DEPLOYMENT }}"
          solo cluster-ref setup -s "${{ env.SOLO_CLUSTER_SETUP_NAMESPACE }}"
          solo network deploy -i node1 --deployment "${{ env.SOLO_DEPLOYMENT }}"
          solo node setup -i node1 --deployment "${{ env.SOLO_DEPLOYMENT }}" --local-build-path ./consensus-node/hedera-node/data
          solo node start -i node1 --deployment "${{ env.SOLO_DEPLOYMENT }}"
          solo mirror-node deploy --deployment "${{ env.SOLO_DEPLOYMENT }}" --cluster-ref kind-${{ env.SOLO_CLUSTER_NAME }}

          kubectl port-forward svc/haproxy-node1-svc -n "${{ env.SOLO_NAMESPACE }}" 50211:non-tls-grpc-client-port &
          kubectl port-forward svc/mirror-monitor -n "${{ env.SOLO_NAMESPACE }}" 5600:http &
          kubectl port-forward svc/mirror-rest -n "${{ env.SOLO_NAMESPACE }}" 5551:http &
          kubectl port-forward svc/mirror-restjava -n "${{ env.SOLO_NAMESPACE }}" 8084:http &

      # Start the TCK client
      - name: Start tck-client
        env:
          OPERATOR_ACCOUNT_ID: "0.0.2"
          OPERATOR_ACCOUNT_PRIVATE_KEY: "302e020100300506032b65700422042091132178e72057a1d7528025956fe39b0b847f200ab59b2fdd367017f3087137"
          JSON_RPC_SERVER_URL: "http://127.0.0.1:8544"
          NODE_IP: "127.0.0.1:50211"
          MIRROR_NODE_REST_URL: "http://127.0.0.1:5551"
          MIRROR_NODE_REST_JAVA_URL: "http://127.0.0.1:8084"
        run: |
          solo account create --dev --ed25519-private-key "${{ env.OPERATOR_ACCOUNT_PRIVATE_KEY }}" --deployment ${{ env.SOLO_DEPLOYMENT }} --hbar-amount 1000000
          cp .env.custom_node .env
          npm run test

      # Stop the TCK server
      - name: Stop tck-server
        if: ${{ always() }}
        run: |
          echo ${{ steps.start-sdk-server.outputs.pid }}
          kill -9 ${{ steps.start-sdk-server.outputs.pid }}

      # Stop the solo nodes
      - name: Stop solo
        if: ${{ always() }}
        run: |
          kind delete cluster -n ${{ env.SOLO_CLUSTER_NAME }}